\section{Discussion}
\subsection{Interpretation of Results}
This study examined how empathic versus neutral AI avatar personalities influence learner engagement and perceived learning in an AI-supported educational environment. Although no statistically significant differences were found in learning scores, sentiment, confusion rates, or response times between the two conditions, the observed divergence in interaction patterns suggests that avatar empathy primarily influenced behavioral engagement rather than short-term cognitive performance.
\\
Participants interacting with the empathic avatar produced longer responses and engaged in more conversational turns compared to those interacting with the neutral avatar. This indicates that empathic language and supportive tone may shape how learners interact with the system, even when measurable learning outcomes remain comparable. In other words, while empathy did not directly translate into higher test performance within this short intervention, it appeared to meaningfully alter the dynamics of the learning interaction.
\\
Interestingly, time spent in the system was not strongly associated with measurable learning gains. This finding suggests that extended interaction alone does not necessarily produce improved short-term knowledge retention. Instead, engagement and learning performance may represent related but distinct dimensions of AI-supported education. This distinction aligns with multidimensional models of engagement, which conceptualize behavioral participation as separate from measurable academic achievement outcomes \cite{fredricks2004engagement}. From this perspective, the empathic avatar may have enhanced behavioral engagement without directly affecting cognitive test performance within the limited duration of the experiment. However, such heightened engagement may potentially serve as a catalyst for long-term academic persistence and motivation, which could yield cognitive benefits over more extended periods of use.
\\
One plausible interpretation is that empathic language increased learners’ sense of responsiveness or social presence, thereby encouraging more elaboration and conversational depth. However, psychological comfort and perceived social presence were not directly measured in this study. While this interpretation cannot be empirically confirmed within the current design, it provides a theoretically grounded explanation that warrants systematic investigation in future research.
\\
Overall, the findings indicate that empathic AI tutoring may function primarily as an engagement catalyst rather than a direct driver of short-term measurable learning gains. This distinction is particularly relevant when evaluating emotionally expressive AI systems in educational contexts.


\subsection{Implications for Human–AI Interaction Design}
The findings of this study offer several implications for the design and evaluation of AI-supported educational systems.
\\
First, emotional tone appears to meaningfully influence interaction behavior, even in the absence of measurable differences in short-term learning performance. Designers of AI tutors should therefore consider engagement-related metrics—such as conversational depth, response length, and interaction density—as complementary indicators of system effectiveness. Evaluating AI learning environments solely based on test performance may overlook important behavioral and experiential dimensions of user interaction.
\\
Second, the results suggest that affective design alone may not be sufficient to produce immediate improvements in measurable learning outcomes. While empathic communication increased behavioral engagement, it did not significantly improve short-term knowledge retention. This indicates that emotional expressiveness should ideally be integrated with structured pedagogical strategies, adaptive scaffolding, and feedback mechanisms to enhance cognitive gains.
\\
Third, the study highlights the importance of distinguishing between engagement and effectiveness in Human–AI Interaction research. An AI system may successfully increase user participation and conversational involvement without directly improving immediate test performance. Recognizing this distinction supports the development of multidimensional evaluation frameworks that capture both experiential and cognitive outcomes.
\\
Finally, the results contribute to broader discussions on social presence in AI systems. While emotionally expressive avatars may enhance user engagement, their impact on measurable learning performance may depend on contextual factors such as intervention duration, task complexity, and learner characteristics. Future design approaches should therefore consider empathy as one component within a broader pedagogical and interactional framework.

\subsection{Limitations}
Several limitations should be considered when interpreting the findings of this study.
\\
First, the sample size was relatively small (N = 30), which limits statistical power and reduces the likelihood of detecting subtle effects. Larger and more diverse samples would enable more robust statistical testing and subgroup analyses.
\\
Second, the intervention was short-term and limited to introductory psychology topics. The absence of significant differences in learning performance may reflect the brief exposure duration rather than the ineffectiveness of empathic design. Longitudinal studies are needed to examine whether empathy influences knowledge retention and deeper cognitive processing over extended periods. Furthermore, the increased engagement observed in the empathic condition may partially reflect a “novelty effect” whereby participants interacted more extensively due to the relative uniqueness of an emotionally expressive AI. Such effects may diminish as users become more accustomed to these systems.
\\
Third, the study relied primarily on self-reported measures and short-term knowledge assessments. While these instruments are common in HAI and educational research, they may not fully capture deeper cognitive processing, long-term retention, or transfer of learning.
\\
Fourth, participants were predominantly university students with prior experience using AI tools. This familiarity may have shaped expectations and interaction styles, potentially limiting the generalizability of the findings to other populations.
\\
Finally, although teaching content was controlled across conditions, dialog-based LLM systems inherently allow dynamic interaction trajectories. Despite prompt engineering to ensure structural consistency, real-time conversational variability may introduce subtle differences that are difficult to fully standardize.
\\
Taken together, these limitations suggest that the findings should be interpreted as exploratory evidence regarding engagement effects rather than definitive conclusions about the role of empathy in AI-supported learning.

