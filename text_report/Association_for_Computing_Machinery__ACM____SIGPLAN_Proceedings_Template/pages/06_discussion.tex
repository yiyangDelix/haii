\section{Discussion}
\subsection{Interpretation of Results}
This study examined how empathic versus neutral AI avatar personalities influence learner engagement and perceived learning in an AI-supported educational environment. While no statistically significant differences were observed in learning scores, sentiment, confusion rates, or response times between the two conditions, clear differences emerged in interaction behavior.
\\
Participants interacting with the empathic avatar produced longer responses and engaged in more conversational turns compared to those interacting with the neutral avatar. These findings suggest that avatar empathy may influence how learners engage with the system, even when measurable short-term learning outcomes remain comparable. In other words, while empathy did not directly translate into higher test performance within this short intervention, it appeared to shape the interaction dynamics of the learning experience.
\\
One possible interpretation is that empathic language may be perceived as more supportive or socially responsive, which could encourage learners to elaborate more extensively in their responses. However, psychological comfort or perceived social presence were not directly measured in this study; therefore, this interpretation remains speculative and should be examined in future research.
\\
Interestingly, although empathic interactions were characterized by greater response length and conversational density, time spent in the system was not strongly associated with measurable learning gains. This suggests that extended interaction alone does not necessarily produce improved short-term knowledge retention. Instead, engagement and learning performance may represent related but distinct dimensions of AI-supported education.
\\
Overall, the findings indicate that empathic AI tutoring may function more as an engagement catalyst rather than a direct driver of short-term measurable learning performance. This distinction is important when evaluating the effectiveness of emotionally expressive AI systems.


\subsection{Implications for Human–AI Interaction Design}
The results provide several implications for the design of Human–AI Interaction in educational contexts.
\\
First, the findings suggest that emotional tone in AI tutors can meaningfully shape user interaction behavior. Even in the absence of statistically significant differences in learning outcomes, empathic design appears to influence how users communicate with the system. Designers of educational AI systems should therefore consider engagement-related metrics—such as conversational depth, response length, and interaction patterns—alongside traditional performance indicators.
\\
Second, the results indicate that affective design alone may not be sufficient to enhance short-term learning outcomes. In this study, empathy did not significantly improve knowledge test scores compared to a neutral instructional style. This suggests that emotional expressiveness should be integrated with structured pedagogical strategies, scaffolding techniques, or adaptive feedback mechanisms to produce measurable learning gains.
\\
Third, the study highlights the importance of distinguishing between engagement and effectiveness. An AI tutor may successfully increase user interaction and conversational participation without necessarily improving immediate test performance. For researchers and practitioners, this distinction emphasizes the need for multi-dimensional evaluation frameworks when assessing AI-supported learning systems.
\\
Finally, the findings contribute to ongoing discussions in HAI research about the role of social presence in AI systems. While emotionally expressive avatars may enhance user engagement, their impact on cognitive learning outcomes may depend on contextual variables such as intervention duration, task complexity, and learner characteristics.

\subsection{Limitations}
Several limitations should be considered when interpreting the findings of this study.
First, the sample size was relatively small (N = 30), which limits statistical power and may reduce the likelihood of detecting subtle effects. Larger samples would allow for more robust statistical testing and subgroup analyses.
\\
Second, the intervention was short-term and limited to introductory psychology topics. The absence of significant learning differences between conditions may reflect the brief exposure duration rather than the ineffectiveness of empathic design. Longitudinal studies are needed to examine whether empathy influences knowledge retention over extended periods.
\\
Third, the study relied primarily on self-reported measures and short-term knowledge tests. While these instruments are commonly used in HAI and educational research, they may not fully capture deeper cognitive processing, long-term retention, or transfer of learning.
\\
Fourth, participants were mostly university students with prior experience using AI tools. This familiarity may have influenced expectations and interaction styles, potentially limiting the generalizability of the findings to other populations.
\\
Finally, although the system is controlled for teaching content across conditions, subtle variations in interaction trajectories may naturally emerge in dialog-based LLM systems. While prompt engineering ensures structural consistency, real-time conversational dynamics may introduce variability that is difficult to standardize fully.
\\
Taken together, these limitations suggest that the findings should be interpreted as exploratory evidence regarding engagement effects rather than definitive conclusions about the role of empathy in AI-supported learning.

